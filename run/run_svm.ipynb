{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model with tabular data\n",
    "\n",
    "\n",
    "https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/#:~:text=A%20support%20vector%20machine%20(SVM,able%20to%20categorize%20new%20text.\n",
    "\n",
    "- binary classification algorithm, supervised learning\n",
    "- calculates best decision boundary (eg. hyperplane) between data with different labels\n",
    "- linear classifier = can only separate linearly separable data\n",
    "- good for small datasets\n",
    "\n",
    "Working with non-linear data:\n",
    "- uses kernel trick: apply a kernel function (eg. dot product of feature vectors). work in the original feature space without computing the coordinates of data in a higher dimension. Its a more efficient way to transform data into a higher dimension where data is more linearly separable.\n",
    "- This is more cost efficient than manually mapping data to a higher dimension (might require lots of dimensions to be added, complex calculations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 Loading dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../examples/adult_icu.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 Loading variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_feature_cols = ['subject_id', 'hadm_id', 'icustay_id', 'train', 'mort_icu', 'adult_icu', 'chartext']\n",
    "feature_cols = np.asarray(df.columns)\n",
    "feature_cols = [feature for feature in feature_cols if feature not in non_feature_cols] # all feature columsn\n",
    "\n",
    "label_col = \"mort_icu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train= x: (18323, 62) , y: (18323,)\nTest= x: (9025, 62) , y: (18323,)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# get train test split by index value\n",
    "idx_train, idx_test, y_train, y_test = train_test_split(df.index, df[label_col].values, test_size=0.33,random_state=109)\n",
    "\n",
    "# get train and test df\n",
    "train_df = df.iloc[idx_train]\n",
    "test_df = df.iloc[idx_test]\n",
    "\n",
    "print(\"Train= x: \" + str(train_df.shape) + \" , y: \" + str(y_train.shape))\n",
    "print(\"Test= x: \" + str(test_df.shape) + \" , y: \" + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Data Processing\n",
    "\n",
    "https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "\n",
    "Things to consider:\n",
    "- data imputation / missing values\n",
    "- Handling outliers\n",
    "    - detect and remove\n",
    "    - detect and capp \n",
    "- Log transform:\n",
    "    - helps to handle skewed data and after transformation, the distribution becomes more approximate to normal.\n",
    "    - In most of the cases the magnitude order of the data changes within the range of the data. For instance, the difference between ages 15 and 20 is not equal to the ages 65 and 70. In terms of years, yes, they are identical, but for all other aspects, 5 years of difference in young ages mean a higher magnitude difference. This type of data comes from a multiplicative process and log transform normalizes the magnitude differences like that.\n",
    "    - It also decreases the effect of the outliers, due to the normalization of magnitude differences and the model become more robust.\n",
    "    - NOTE: The data you apply log transform must have only positive values, otherwise you receive an error. Also, you can add 1 to your data before transform it. Thus, you ensure the output of the transformation to be positive.\n",
    "- One-hot-encoding:\n",
    "    - This method changes your categorical data, which is challenging to understand for algorithms, to a numerical format and enables you to group your categorical data without losing any information.\n",
    "- scaling:\n",
    "    - makes sure different scales don't affect model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 Feature scaling (normalizing / standardizing)\n",
    "\n",
    "SVM:\n",
    "- Recommend standardizing (from 0,1) because feature scales influence the optimal hyperplane\n",
    "\n",
    "https://machinelearningmastery.com/normalize-standardize-time-series-data-python/\n",
    "https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/\n",
    "\n",
    "Scaling features:\n",
    "- purpose: Having features on a similar scale can help the gradient descent converge more quickly towards the minima.\n",
    "- distance based algorithms: we scale our data before employing a distance based algorithm so that all the features contribute equally to the result. \n",
    "\n",
    "Normalization: numbers scaled from 0 to 1 --> can use sk learn MinMaxScaler\n",
    "- Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.\n",
    "\n",
    "Standardizing: rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1.\n",
    "- Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.\n",
    "\n",
    "- However, at the end of the day, the choice of using normalization or standardization will depend on your problem and the machine learning algorithm you are using. There is no hard and fast rule to tell you when to normalize or standardize your data. You can always start by fitting your model to raw, normalized and standardized data and compare the performance for best results.\n",
    "\n",
    "\n",
    "Types of scalers:\n",
    "https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "- StandardScaler: removes the mean and scales the data to unit variance\n",
    "    - outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values\n",
    "    - cannot guarantee balanced feature scales in the presence of outliers\n",
    "- minmax scaler: normalizing to [0,1], sensitive to outliers\n",
    "- maxabs scaler: absolute values scaled to [0,1], sensitive to outliers\n",
    "- robust scaler: the centering and scaling statistics based on percentiles\n",
    "    - not influenced by a few number of very large marginal outliers. \n",
    "    - resulting range of the transformed feature values is larger and are approximately similar. \n",
    "    - Outliers themselves are still present in the transformed data\n",
    "- power transformer: applies a power transformation to each feature to make the data more Gaussian-like. \n",
    "    - Currently, PowerTransformer implements the Yeo-Johnson and Box-Cox transforms\n",
    "    -  finds the optimal scaling factor to stabilize variance and mimimize skewness through maximum likelihood estimation\n",
    "\n",
    "- QuantileTransformer: \n",
    "    - has an additional output_distribution parameter allowing to match a Gaussian distribution instead of a uniform distribution. Note that this non-parametetric transformer introduces saturation artifacts for extreme values\n",
    "    - also can apply a non-linear transformation such that the probability density function of each feature will be mapped to a uniform distribution. In this case, all the data will be mapped in the range [0, 1], even the outliers which cannot be distinguished anymore from the inliers\n",
    "    - robust to outliers in the sense that adding or removing outliers in the training set will yield approximately the same transformation on held out data. But contrary to RobustScaler, QuantileTransformer will also automatically collapse any outlier by setting them to the a priori defined range boundaries (0 and 1).\n",
    "\n",
    "- normalizer:\n",
    "    - rescales the vector for each sample to have unit norm, independently of the distribution of the samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def fit_scaler(train_df, features_list: list, scale_type: str):\n",
    "    \"\"\"\n",
    "    Fit scaler on train data\n",
    "    inputs:\n",
    "    - train_df: dataframe of x train data\n",
    "    - features_list: list of features to be scaled\n",
    "    - scale_type: type of scale to use (ie. standardize, normalize)\n",
    "\n",
    "    scalers takes input (num_samples, num_features) and scales all features\n",
    "    \"\"\"\n",
    "    scaler_dict = {\n",
    "        \"standard\" : StandardScaler(), \n",
    "        \"minmax\" : MinMaxScaler(feature_range=(0, 1)) , \n",
    "        \"maxabs\" : MaxAbsScaler(), \n",
    "        \"robust\": RobustScaler(quantile_range=(25, 75)),\n",
    "        \"power_yeo_johnson\": PowerTransformer(method='yeo-johnson'),\n",
    "        \"power_box_cox\" : PowerTransformer(method='box-cox'),\n",
    "        \"quartile_normal\":  QuantileTransformer(output_distribution='normal'),\n",
    "        \"quartile_uniform\": QuantileTransformer(output_distribution='uniform'),\n",
    "        \"normalizer\": Normalizer()\n",
    "    }\n",
    "    \n",
    "    scaler = scaler_dict[scale_type].fit(train_df[features_list])\n",
    "\n",
    "    return scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Non binary features that are standardized: ['age', 'heartrate_min', 'heartrate_max', 'heartrate_mean', 'sysbp_min', 'sysbp_max', 'sysbp_mean', 'diasbp_min', 'diasbp_max', 'diasbp_mean', 'meanbp_min', 'meanbp_max', 'meanbp_mean', 'resprate_min', 'resprate_max', 'resprate_mean', 'tempc_min', 'tempc_max', 'tempc_mean', 'spo2_min', 'spo2_max', 'spo2_mean', 'glucose_min', 'glucose_max', 'glucose_mean', 'aniongap', 'albumin', 'bicarbonate', 'bilirubin', 'creatinine', 'chloride', 'glucose', 'hematocrit', 'hemoglobin', 'lactate', 'magnesium', 'phosphate', 'platelet', 'potassium', 'ptt', 'inr', 'pt', 'sodium', 'bun', 'wbc']\n"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# All non-binary features need to be standardized\n",
    "binary_features = ['subject_id', 'hadm_id', 'icustay_id', 'mort_icu', 'first_icu_stay', 'first_hosp_stay', 'adult_icu', 'eth_asian', 'eth_black', 'eth_hispanic', 'eth_other','eth_white', 'admType_ELECTIVE', 'admType_EMERGENCY', 'admType_NEWBORN', 'admType_URGENT', 'admType_ELECTIVE', 'train', 'chartext']\n",
    "\n",
    "# Get all feature columns that are non-binary\n",
    "nonbinary_features = [feature for feature in feature_cols if feature not in binary_features]\n",
    "print(\"Non binary features that are standardized: \" + str(nonbinary_features))\n",
    "\n",
    "# Fit the standardized scaler on the TRAIN data\n",
    "scaler = fit_scaler(train_df, nonbinary_features, \"standard\")\n",
    "\n",
    "# Tranform both TRAIN and TEST data on the scaler fitted on TRAIN data\n",
    "train_df[nonbinary_features] = scaler.transform(train_df[nonbinary_features])\n",
    "test_df[nonbinary_features] = scaler.transform(test_df[nonbinary_features])\n",
    "\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 Obtain X_TRAIN, Y_TRAIN, X_TEST, Y_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x train: (18323, 56)\ny train: (18323,)\nx train: (9025, 56)\ny train: (9025,)\n"
    }
   ],
   "source": [
    "# identify feature columns\n",
    "label_col = \"mort_icu\"\n",
    "non_feature_cols = ['subject_id', 'hadm_id', 'icustay_id', 'train', 'mort_icu', 'adult_icu', 'chartext']\n",
    "feature_cols = np.asarray(df.columns)\n",
    "feature_cols = [feature for feature in feature_cols if feature not in non_feature_cols] # all feature columsn\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "# x_train, y_train\n",
    "num_train = len(train_df)\n",
    "x_train = train_df[feature_cols].values.reshape(num_train, num_features)\n",
    "y_train = train_df[label_col].values.reshape(num_train,)\n",
    "\n",
    "print(\"x train: \" + str(x_train.shape))\n",
    "print(\"y train: \" + str(y_train.shape))\n",
    "\n",
    "# x_test, y_test\n",
    "num_test= len(test_df)\n",
    "x_test = test_df[feature_cols].values.reshape(num_test, num_features)\n",
    "y_test = test_df[label_col].values.reshape(num_test,)\n",
    "\n",
    "print(\"x train: \" + str(x_test.shape))\n",
    "print(\"y train: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.1 Kernel function:\n",
    "\n",
    "Kernel trick:\n",
    "https://medium.com/@zxr.nju/what-is-the-kernel-trick-why-is-it-important-98a98db0961d\n",
    "- allows you to operate in the original feature space without computing the coordinates of the data in a higher dimensional space.\n",
    "- can be applied to any linear classifier\n",
    "- offer a more efficient and less expensive way to transform data into higher dimensions\n",
    "\n",
    "Types of kernel functions:\n",
    "\n",
    "https://data-flair.training/blogs/svm-kernel-functions/#:~:text=The%20function%20of%20kernel%20is,(RBF)%2C%20and%20sigmoid.\n",
    "\n",
    "http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/\n",
    "\n",
    "\n",
    "- linear kernel:\n",
    "    - inner product + optional constant\n",
    "    - like standard PCA \n",
    "\n",
    "- polynomial kernel: \n",
    "    - non-stationary kernel\n",
    "    - good for normalized data\n",
    "    - popular in image processing\n",
    "\n",
    "- gaussian radial basis function kernel:\n",
    "    - There is an infinite number of dimensions in the feature space because it can be expanded by the Taylor Series.\n",
    "    - general purpose, good when you have no prior knowledge about data\n",
    "    - sigma (adjustable parameter) needs to be carefully tuned to problem. \n",
    "        - if overestimated, function will behave linearly (ie. lose non-linear power). \n",
    "        - if underestimated, function will lack regularitzation and decision boundary will be highly sensity to noise (ie. overfitted)\n",
    "\n",
    "- inverse multiquadric kernel:\n",
    "    - results in kernel matrix with full rank --> forms infinite dimension feature space\n",
    "\n",
    "- exponential radial basis function kernel:\n",
    "    - similar to gaussian kernel, without the square of norm\n",
    "    - sigma (adjustable parameter) needs to be carefully tuned to problem. \n",
    "        - if overestimated, function will behave linearly (ie. lose non-linear power). \n",
    "        - if underestimated, function will lack regularitzation and decision boundary will be highly sensity to noise (ie. overfitted)\n",
    "\n",
    "- laplace radial basis function kernel: \n",
    "    - general purpose, good when you have no prior knowledge about data\n",
    "    - same as exponential rbf, but less sensitive to changes in sigma parameter\n",
    "    - sigma (adjustable parameter) needs to be carefully tuned to problem. \n",
    "        - if overestimated, function will behave linearly (ie. lose non-linear power). \n",
    "        - if underestimated, function will lack regularitzation and decision boundary will be highly sensity to noise (ie. overfitted)\n",
    "\n",
    "- ANOVA radial basis function kernel:\n",
    "    - perform well on multidimensional regression problems \n",
    "\n",
    "- hyperbolic tangent (sigmoid / MLP) kernal:\n",
    "    - comes from neural network field (bipolar sigmoid function often used as activation function)\n",
    "    - SVM usign sigmoid kernal is the same as 2 layer perceptron network \n",
    "    - performs well in practise for SVM\n",
    "\n",
    "- Rational quadratic kernel or multiquadric kernel:\n",
    "    - can replace gaussian rbf kernel because its less computationally expensive\n",
    "\n",
    "- cauchy kernel:\n",
    "    - give long-range influence and sensitivity over high dimension space\n",
    "    - long-tailed kernel\n",
    "\n",
    "- circular kernel or spherical kernel:\n",
    "    - used in geostatic application\n",
    "\n",
    "- power kernel:\n",
    "    - scale-invariant kernel\n",
    "    - unrectified triangular kernel\n",
    "\n",
    "- log kernel:\n",
    "    - interesting for images\n",
    "\n",
    "\n",
    "Cons of kernel trick:\n",
    "- higher dimension --> increased chance of overfitting. therefore choosing the right kernel function and the right regulation method is key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.2 Hyperparameter tuning \n",
    "https://towardsdatascience.com/a-guide-to-svm-parameter-tuning-8bfe6b8a452c\n",
    "\n",
    "C: penalty parameter\n",
    "- tells algorithm how much you care about misclassified points\n",
    "    - high: penalize misclassified more - more accurate to current data but could overfit\n",
    "    - low: penalize misclassfied less - less accurate to current data but more generalizable\n",
    "\n",
    "gamma: spread of kernel / decision region\n",
    "    - low = curve of decision boundary is low (like a linear boundary)\n",
    "    - high = curve of devision boundary is high (can overfit)\n",
    "\n",
    "https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/auto_examples/svm/plot_svm_parameters_selection.html\n",
    "\n",
    "Stratified K-Fold crossvalidation:\n",
    "- to set hyperparameters (C, gamma)\n",
    "- strafied = ensures that there are equal number of data from each label\n",
    "- k = N : leave one out validation (predict on one sample)\n",
    "- k = usually 5 or 10, but no formal rule\n",
    "    - k gets larger = difference in size between training set and resampling subset gets smaller = bias decreases\n",
    "    - 10 is good place to start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def report_best_params(x_train: np.array, y_train: np.array, params: dict, estimator, n_splits: int):\n",
    "    \"\"\"\n",
    "    x_train: np array of train data\n",
    "    y_train: np array of train data labels\n",
    "    params: range of parameters to test\n",
    "    estimator: type of model\n",
    "    n_splits: number of splits for cv validation\n",
    "    \"\"\"\n",
    "\n",
    "    grid = GridSearchCV(estimator=estimator, param_grid=params, refit = True, cv= StratifiedKFold(n_splits=n_splits))\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    print(\"The best classifier is: \", grid.best_estimator_)\n",
    "\n",
    "    print(\"The best parameters are: \" + str(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The best classifier is:  SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"dict\") to str",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f03c8ed1e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# params = [{'kernel': ['rbf'], 'gamma': 10. ** np.arange(-5, 5),'C': 10. ** np.arange(-2, 5)},{'kernel': ['linear'], 'C': 10. ** np.arange(-2, 5)}]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mreport_best_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-76d61bc1f09e>\u001b[0m in \u001b[0;36mreport_best_params\u001b[0;34m(x_train, y_train, params, estimator, n_splits)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The best classifier is: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The best parameters are: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"dict\") to str"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#  define parameters to tune for svm     \n",
    "    # refine these as you go\n",
    "params = [{'kernel': ['rbf'], 'gamma': [0.1, 1, 100],'C': [0.1, 1, 100]}]\n",
    "\n",
    "# uncomment for better range\n",
    "# params = [{'kernel': ['rbf'], 'gamma': 10. ** np.arange(-5, 5),'C': 10. ** np.arange(-2, 5)},{'kernel': ['linear'], 'C': 10. ** np.arange(-2, 5)}]\n",
    "\n",
    "report_best_params(x_train, y_train, params, SVC(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.3 SVM model with optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n    max_iter=-1, probability=False, random_state=None, shrinking=True,\n    tol=0.001, verbose=False)"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "kernel = \"rbf\"\n",
    "c = 0.1\n",
    "gamma = 0.1\n",
    "\n",
    "model = SVC(kernel=kernel, C=c, gamma=gamma)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D.4 Making and evaluating predictions\n",
    "\n",
    "evaluate prediction using AUC score \n",
    "- AUC score: represents degree or measure of separability (ie. how well a model is able to distinguish between classes)\n",
    "    - area under the ROC curve (TPR and FPR are clearly separated)\n",
    "\n",
    "- scale-invariant. It measures how well predictions are ranked, rather than their absolute values.  \n",
    "    - note: not good if you need well calibrated outputs\n",
    "    \n",
    "- classification-threshold-invariant. It measures the quality of the model's predictions irrespective of what classification threshold is chosen.\n",
    "    - note: not be good if cost of FP and FN are significantly different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AUC score: 0.7750250452075597\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "print(\"AUC score: \" + str(roc_auc))\n",
    "\n",
    "# evaluate prediction using ROC graph\n",
    "plt.title('ROC curve')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}